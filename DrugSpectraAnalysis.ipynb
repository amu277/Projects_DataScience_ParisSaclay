{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <a href=http://www.datascience-paris-saclay.fr/>Paris Saclay Center for Data Science</a> </h1>\n",
    "\n",
    "<h2> RAMP on qualitative and quantitative non-invasive monitoring of anti-cancer drugs </h2>\n",
    "\n",
    "<i>Camille Marini (LTCI/CNRS), Alex Gramfort (LTCI/Télécom ParisTech), Sana Tfaili (Lip(Sys)²/UPSud), Laetitia Le (Lip(Sys)²/UPSud), Mehdi Cherti (LAL/CNRS), Balázs Kégl (LAL/CNRS)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Spectra: Fall 2016 - Arpa MUKHERJEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "y_df = data[['molecule', 'concentration']]\n",
    "X_df = data.drop(['molecule', 'concentration'], axis=1)\n",
    "spectra = X_df['spectra'].values                                        \n",
    "spectra = np.array([np.array(dd[1:-1].split(',')).astype(float) for dd in spectra])    \n",
    "X_df['spectra'] = spectra.tolist()\n",
    "\n",
    "# Loading wavenumbers\n",
    "freqs = pd.read_csv('freq.csv')\n",
    "freqs = freqs['freqs'].values\n",
    "\n",
    "# Types of molecules\n",
    "types = np.unique(y_df['molecule'].values)\n",
    "# print(types)\n",
    "\n",
    "# Target for classification\n",
    "molecule = y_df['molecule'].values\n",
    "# Target for regression\n",
    "concentration = y_df['concentration'].values\n",
    "# \"Raw\" features\n",
    "X = spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Data Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This was just to look at descriptive stats for all the data sources to get an idea based on pandas.df.describe\n",
    "\n",
    "def describe_adj(df):\n",
    "    objects = []\n",
    "    numerics = []\n",
    "    for c in df:\n",
    "        if (df[c].dtype == object):\n",
    "            objects.append(c)\n",
    "        else:\n",
    "            numerics.append(c)\n",
    "\n",
    "    return df[objects].describe(), df[numerics].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "describe_adj(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Raman spectra viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot before and after filter which I used for the feature extraction.\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "spectra1 = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "spectra_sgsmooth = savgol_filter(spectra1, 15, 3) # window size 5, polynomial order 3\n",
    "\n",
    "\n",
    "bx = plt.subplot('211')\n",
    "bx.set_title(\"Original Spectra\")\n",
    "plt.plot(freqs, spectra.T)\n",
    "bx2 = plt.subplot('212')\n",
    "bx2.set_title(\"Savitsky Golay Filter\")\n",
    "plt.plot(freqs, spectra_sgsmooth.T)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Concentration viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To see the frequency of concentration by molecule in a different form and to get an understanding of the distribution.\n",
    "# Helps to inform which regressor to choose.\n",
    "\n",
    "def stbars(df, conc, mtype):\n",
    "\n",
    "    mtype_list = data[mtype].unique()\n",
    "    conc_list = data[conc].unique()\n",
    "  \n",
    "    # outer:\n",
    "    outdict = {}\n",
    "    for m in mtype_list:\n",
    "        m_df = df[df[mtype]==m]\n",
    "        m_count = m_df.groupby(conc).count() \n",
    "        \n",
    "        # inner:\n",
    "        indict ={}\n",
    "        for x in conc_list:\n",
    "            indict[x] = (m_count.loc[x].values[0] if x in m_count.index.values else 0)\n",
    "        outdict[m] = indict\n",
    "        \n",
    "    return pd.DataFrame(outdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_mol_conc = stbars(data,\"concentration\",\"molecule\")\n",
    "colors = ['#624ea7', 'g', 'yellow', 'k', 'maroon']\n",
    "ax = df_mol_conc.plot.barh(stacked=True, figsize=[9,4], color=colors)\n",
    "ax.set_title(\"Concentration per molecule\")\n",
    "ax.set_xlabel(\"Count\")\n",
    "ax.set_ylabel(\"Concentrations\")\n",
    "print(df_mol_conc) # note to self: maybe use this data to calculate weights for RFR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this was spectral data, I only thought to apply a filter, and after some research decided to choose the Savitzky-Golay filter to smooth the data as it does not distort the signal too much. I found it made a slight improvement compared to the original. I read in theory for smoothing effect to appear, the polynomial order should be less than the window size, and I chose a ratio of 1/5 (3 vs 15) after some testing. I tested adding PCA also with the filter but it seemed to worsen the classifier results, so I decided to keep it out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "class FeatureExtractorClf(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_df, y_df):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X_df):\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])\n",
    "        XX_sgsmooth = savgol_filter(XX, 15, 3) # window size 15, polynomial order 3\n",
    "        return XX_sgsmooth\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification: predicting the molecule type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first decided to choose the classifier SVM with its default properties instead of logistic regression because the number of features is small compared to the number of training examples. At first I had included PCA with SVC, and then decided to switch to Stochastic Gradient Descent Classifier in the pipeline, and this coupled with SVC with kernel set to linear really improved the results. Additionally, adjusting the penalty parameter with SVC, C, to higher results, helped to further minimize error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    " \n",
    " \n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = Pipeline([\n",
    "            ('sgd', SGDClassifier(loss='hinge', penalty='l2')),\n",
    "            ('clf', SVC(kernel='linear', C = 100000, probability=True)),\n",
    "        ])\n",
    " \n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    " \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    " \n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.03\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          A       0.97      0.97      0.97        63\n",
      "          B       0.95      0.93      0.94        45\n",
      "          Q       1.00      0.97      0.99        40\n",
      "          R       0.96      1.00      0.98        52\n",
      "\n",
      "avg / total       0.97      0.97      0.97       200\n",
      "\n",
      "confusion matrix:\n",
      " [[61  2  0  0]\n",
      " [ 1 42  0  2]\n",
      " [ 1  0 39  0]\n",
      " [ 0  0  0 52]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    "\n",
    "def train_test_model_clf(X_df, y_df, skf_is, FeatureExtractor, Classifier):\n",
    "    train_is, test_is = skf_is\n",
    "    X_train_df = X_df.iloc[train_is].copy()                                  \n",
    "    y_train_df = y_df.iloc[train_is].copy()\n",
    "    y_train_clf = y_train_df['molecule'].values\n",
    "    X_test_df = X_df.iloc[test_is].copy()                                    \n",
    "    y_test_df = y_df.iloc[test_is].copy() \n",
    "    y_test_clf = y_test_df['molecule'].values \n",
    "    # Feature extraction\n",
    "    fe_clf = FeatureExtractor()\n",
    "    fe_clf.fit(X_train_df, y_train_df)\n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)\n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)\n",
    "    # Train\n",
    "    clf = Classifier()\n",
    "    clf.fit(X_train_array_clf, y_train_clf)\n",
    "    # Test \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]                      \n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = %s' % error)                                                                            \n",
    "    print('classification report:\\n %s' % classification_report(y_test_clf, y_pred_clf))\n",
    "    print('confusion matrix:\\n %s' % confusion_matrix(y_test_clf, y_pred_clf))\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57)  \n",
    "skf_is = list(skf.split(X_df))[0]\n",
    "\n",
    "train_test_model_clf(X_df, y_df, skf_is, FeatureExtractorClf, Classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extractor for regression\n",
    "\n",
    "I started with PCA at its default setting since we have both molecule types and spectra data with some multicollinearity. The main adjustment here I made is to set it to randomized PCA which does not center the data as in the regular SVD used by PCA and seemed to offer slightly better results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    " \n",
    "labels = np.array(['A', 'B', 'Q', 'R'])\n",
    " \n",
    "class FeatureExtractorReg(object):\n",
    "    def __init__(self):\n",
    "        self.pca = PCA(n_components=10, svd_solver = 'randomized') # Add randomized PCA\n",
    " \n",
    "    def fit(self, X_df, y):\n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])  \n",
    "        XX -= np.mean(XX, axis=1)[:, None]                                     \n",
    "        XX /= np.sqrt(np.sum(XX ** 2, axis=1))[:, None]\n",
    "        self.pca.fit(XX)\n",
    "    \n",
    "    def transform(self, X_df):                                                   \n",
    "        XX = np.array([np.array(dd) for dd in X_df['spectra']])                  \n",
    "        XX -= np.mean(XX, axis=1)[:, None]                                     \n",
    "        XX /= np.sqrt(np.sum(XX ** 2, axis=1))[:, None]\n",
    "        XX = self.pca.transform(XX) \n",
    "        XX = np.concatenate([XX, X_df[labels].values], axis=1)                 \n",
    "        return XX   \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression: predicting the concentration\n",
    "\n",
    "I left PCA in the pipeline at first, and I experimented with both Gradient Boosting Regressor vs AdaBoost Regressor, with the latter offering a slightly better score. I decided to keep AdaBoost Regressor and pair with Random Forest Regressor because the concentration data for each molecule type is very unevenly distributed and I thought the Random Forest may learn better, and the pairing with AdaBoost seems to give good performance in general. I experimented with several parameters of Random Forest but could not seem to improve the results too much. My next approach would be to compute and add in weights from the training data for each molecule at each concentration and implement the 'min_weight_leaf' feature of RFR.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    " \n",
    "class Regressor(BaseEstimator):                                                  \n",
    "    def __init__(self):                                                          \n",
    "        self.n_components = 10                                                  \n",
    "#        self.n_estimators = 80                                                   \n",
    "#        self.learning_rate = 0.2                                              \n",
    "        self.list_molecule = ['A', 'B', 'Q', 'R']   \n",
    "        self.dict_reg = {}                                                       \n",
    "        for mol in self.list_molecule:  \n",
    "            self.dict_reg[mol] = Pipeline([('pca', PCA(n_components=self.n_components, random_state=42)),\n",
    "              ('reg', SVC(probability=True,C=100000,gamma=10.0,kernel='linear'))])\n",
    "            \n",
    "#         self.dict_reg['R'] = AdaBoostClassifier(\n",
    "#          RandomForestClassifier(criterion='entropy', n_estimators=self.n_estimators), n_estimators=self.n_estimators, \n",
    "#         learning_rate=self.learning_rate, algorithm=\"SAMME\")\n",
    "         \n",
    "    def fit(self, X, y):\n",
    "        self.viewed = {}\n",
    "        for i, mol in enumerate(self.list_molecule):\n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]\n",
    "            XX_mol = X[ind_mol]\n",
    "            y_mol = y[ind_mol]\n",
    "            self.dict_reg[mol].fit(XX_mol, y_mol.astype(str))\n",
    "            self.viewed[mol] = list(set(y_mol))\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        for i, mol in enumerate(self.list_molecule):\n",
    "            ind_mol = np.where(np.argmax(X[:, -4:], axis=1) == i)[0]\n",
    "            XX_mol = X[ind_mol]\n",
    "            y_pred[ind_mol] =(self.dict_reg[mol].predict(XX_mol).astype(float))\n",
    "        return y_pred\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error =  0.04\n",
      "mare =  0.0421071428571\n",
      "combined error =  0.0407023809524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def mare_score(y_true, y_pred):                                                  \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) \n",
    "\n",
    "def train_test_model(X_df, y_df, skf_is, FeatureExtractorClf, Classifier, FeatureExtractorReg, Regressor):\n",
    "    train_is, test_is = skf_is\n",
    "    X_train_df = X_df.iloc[train_is].copy()                                  \n",
    "    y_train_df = y_df.iloc[train_is].copy()                                  \n",
    "    X_test_df = X_df.iloc[test_is].copy()                                    \n",
    "    y_test_df = y_df.iloc[test_is].copy()                                    \n",
    "    y_train_clf = y_train_df['molecule'].values                              \n",
    "    y_train_reg = y_train_df['concentration'].values                         \n",
    "    y_test_clf = y_test_df['molecule'].values                                \n",
    "    y_test_reg = y_test_df['concentration'].values                           \n",
    "\n",
    "    # Classification\n",
    "    fe_clf = FeatureExtractorClf()                     \n",
    "    fe_clf.fit(X_train_df, y_train_df)                                       \n",
    "    X_train_array_clf = fe_clf.transform(X_train_df)                         \n",
    "    X_test_array_clf = fe_clf.transform(X_test_df)                           \n",
    "                                                                                 \n",
    "    clf = Classifier()                                            \n",
    "    clf.fit(X_train_array_clf, y_train_clf)                                  \n",
    "    y_proba_clf = clf.predict_proba(X_test_array_clf)                        \n",
    "    y_pred_clf = labels[np.argmax(y_proba_clf, axis=1)]                      \n",
    "    error = 1 - accuracy_score(y_test_clf, y_pred_clf)                       \n",
    "    print('error = ', error)\n",
    "    \n",
    "    # Regression\n",
    "    fe_reg = FeatureExtractorReg()                     \n",
    "    for i, label in enumerate(labels):\n",
    "        # For training, we use \n",
    "        X_train_df.loc[:, label] = (y_train_df['molecule'] == label)         \n",
    "        X_test_df.loc[:, label] = y_proba_clf[:, i]                          \n",
    "    fe_reg.fit(X_train_df, y_train_reg)                                      \n",
    "    X_train_array_reg = fe_reg.transform(X_train_df)                         \n",
    "    X_test_array_reg = fe_reg.transform(X_test_df)                           \n",
    "                                                                                 \n",
    "    reg = Regressor()                                              \n",
    "    reg.fit(X_train_array_reg, y_train_reg)                               \n",
    "    y_pred_reg = reg.predict(X_test_array_reg)\n",
    "    mare = mare_score(y_test_reg, y_pred_reg)\n",
    "    print('mare = ', mare)                \n",
    "    print('combined error = ', 2. / 3 * error + 1. / 3 * mare)\n",
    "\n",
    "\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.2, random_state=57) \n",
    "skf_is = list(skf.split(X_df))[0]\n",
    "\n",
    "train_test_model(X_df, y_df, skf_is, FeatureExtractorClf, Classifier, FeatureExtractorReg, Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
